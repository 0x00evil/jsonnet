<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title>Jsonnet - The Data Templating Language</title>
    <meta http-equiv="Content-type" content="text/html;charset=UTF-8" />
    <meta name="keywords" content="Jsonnet, JSON, YAML, language, configuration, configuration language, functional, declarative, lazy, structured, elegant, semantics, clean, mixins, inheritance, template, expansion, expand" />
    <meta name="description" content="The Jsonnet language allows elegant and easy description of JSON data." />

    <link rel="icon" type="image/png" href="favicon.png" />

    <link rel="stylesheet" href="prism.css" />
    <link rel="stylesheet" type="text/css" href="doc.css" />

    <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-53570216-1', 'auto');
      ga('send', 'pageview');

    </script>

    <script src="prism.js" type="text/javascript">
    </script>

    <script type="text/javascript">
    Prism.languages.jsonnet = {
      'cppcomment': /\/\/.*/g,
      'comment': /\/\*[\w\W]*?\*\//g,
      'string': /("|')(\\?.)*?\1/g,
      'keyword': /\b(self|super)\b|\$/g,
      'boolean': /\b(true|false)\b/g,
      'constant': /\bnull\b/g,
      'error': /\berror\b/g,
      'special': /\b(local|function|if|then|else|import|importstr|for|in)\b/g,
      'number': /\b[0-9][0-9.eE]*\b/g,
      'operator': /(\+|\*|\/)+/g,
    };
    </script>

    <style type="text/css">
    .token.comment,
    .token.cppcomment {
      color: #040;
    }

    .token.identifier {
      color: #000;
    }
    .token.operator {
      color: #000;
    }

    .token.boolean,
    .token.number,
    .token.constant {
      color: #05a;
    }

    .token.string {
      color: #000048;
    }

    .token.keyword,
    .token.special {
      color: blue;
    }

    .token.error {
      color: red;
    }
    </style>


    <script type="text/javascript">

        var menu_timeout = null;

        function set_visible(menu, b)
        {
            var category = menu.children[0];
            var dropdown = menu.children[1];
            category.style['border-radius'] = b && dropdown != null ? '4px 4px 0px 0px' : '4px';
            if (dropdown != null) {
                dropdown.style.visibility = b ? 'visible' : 'hidden';
            }
        }

        function menu_open(el)
        {
            menu_close_all();
            var menu = el;
            while (menu.id === "") {
                menu = menu.parentNode;
            }
            set_visible(menu, true);
        }

        function menu_leave()
        {
            if (menu_timeout != null) {
                window.clearTimeout(menu_timeout);
            }
            menu_timeout = window.setTimeout(menu_close_all, 300);
        }

        function menu_close_all()
        {
            var mb = document.getElementById("menubar");
            if (mb == null) return;
            var menus = mb.children;
            for (var i = 0 ; i < menus.length ; ++i) {
                set_visible(menus[i], false);
            }
            if (menu_timeout != null) {
                window.clearTimeout(menu_timeout);
                window_timeout = null;
            }
        }

        document.onclick = menu_close_all(); 

    </script>

</head>

<body class="language-jsonnet">

<div class="header">

<div class="tagline"><i>The data templating language</i></div>
<div id="githubmarkbox">
<a href="https://groups.google.com/forum/#!forum/jsonnet"><div id="groupsmark"></div></a>
<a href="http://github.com/google/jsonnet"><div id="githubmark"></div></a>
</div>
<div class="title"><a href="index.html" class="title">Jsonnet</a></div>

<ol id="menubar">

    <li id="menu_home">
        <a href="index.html" onmouseover="menu_open(this)" onmouseout="menu_leave()">Home</a>
    </li>

    <li id="menu_userdocs">
        <a href="userdocs.html" onmouseover="menu_open(this)" onmouseout="menu_leave()">User docs</a>
        <div onmouseover="menu_open(this)" onmouseout="menu_leave()">
            <a href="tutorial.html">Tutorial</a>
            <a href="demo.html">Demo</a>
            <a href="stdlib.html">Standard Library</a>
        </div>
    </li>

    <li id="menu_language">
        <a href="language.html" onmouseover="menu_open(this)" onmouseout="menu_leave()">Language</a>
        <div onmouseover="menu_open(this)" onmouseout="menu_leave()">
            <a href="design.html">Design</a>
            <a href="comparisons.html">Comparisons</a>
            <a href="spec.html">Specification</a>
        </div>
    </li>

    <li id="menu_implementation">
        <a href="implementation.html" onmouseover="menu_open(this)" onmouseout="menu_leave()">Implementation</a>
        <div onmouseover="menu_open(this)" onmouseout="menu_leave()">
            <a href="commandline.html">Cmdline Tool</a>
            <a href="bindings.html">Libraries</a>
            <a href="cpp.html">C++ Internals</a>
            <a href="javascript.html">Javascript</a>
            <a href="tests.html">Tests</a>
        </div>
    </li>

    <li id="menu_contributing">
        <a href="contributing.html" onmouseover="menu_open(this)" onmouseout="menu_leave()">Contributing</a>
    </li>

</ol>

<div style="clear: both"></div>

</div>



<h1 id=top>Case Study: Cloud Application</h1>

<div id=contents>
    <div>
        <a href="#intro">Introduction</a>
    </div>
    <div>
        <a href="#app">Example Web Application</a>
    </div>
    <div>
        <a href="#config">Configuration Structure</a>
        <div><a href="#config_whirlwind">Whirlwind Tour</a></div>
    </div>
    <div>
        <a href="#using">Using The Configuration</a>
        <div><a href="#using_deploy">Initial Deployment and Tear Down</a></div>
        <div><a href="#using_cassandra">Add / Remove Cassandra Nodes</a></div>
        <div><a href="#using_appserv">Canary Change to Application Server</a></div>
    </div>

</div>

<div style="clear:both"></div>

<h2 id=intro>Introduction</h2>

<p> This case study illustrates that <a href="index.html">Jsonnet</a> can be used to centralize,
unify, and manage configuration for all parts of a cloud hosted multi-tier web application (a
Mandelbrot viewer).  Jsonnet centralizes configuration files for the various application software,
database schemas and initial data sets, system configuration files, package manifests, software
build configurations, image configurations (<a href="http://www.packer.io/">Packer</a>) and cloud
resources / connectivity (<a href="http://www.terraform.io/">Terraform</a>).  Although the running
example is deployed on <a href="https://cloud.google.com">Google Cloud Platform</a> and uses
specific application software, Jsonnet can be used to generate configuration for any application and
(via Packer &amp; Terraform) a wide range of cloud providers.</p>

<p>  Prerequisites: It is assumed that the reader has read the Jsonnet <a
href="tutorial.html">tutorial</a>, and has a basic knowledge of Packer and Terraform.</p>

<h2 id=app>Example Web Application</h2>

<a href="fractal_screenshot.png"><img src="fractal_screenshot.png" class=thumb></a>

<p>The example application allows the user to zoon and pan a Mandelbrot fractal (dynamically
rendered server side, in C++).  The user is able to
save the location of features they find, deep in the fractal, and a time-ordered list of these with
thumbnails is displayed in the left hand pane.  The application is provisionally hosted <a
href="http://fractal.noip.me/">here</a>, but you can easily deploy your own as all required files
are available in the Jsonnet repository.</p>

<p>Although admittedly a little contrived, this example is intended to represent the structure of a
typical non-trivial real-world web application.  It consists of 3 tiers (illustrated below):  An
application server, a backend database (Cassandra) and a backend service for generating the fractal
PNG tiles (C++).  Each tier is scalable and fault-tolerant.</p>

<img src="fractal_architecture.png">

<p>The application server hosts static content (CSS) and Jinja'd HTML.  The HTML <a
href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/appserv/templates/page.html">contains</a> Javascript that issues AJAX
requests to 1) the tile generation backend and 2) the application server (to fetch / amend the
discoveries list).  The application server therefore does not communicate directly with the fractal
tile generation service, but it needs to know the host:port endpoint in order to embed it in the
HTML so that the user's browser can do so.  The user does not communicate directly with the
Cassandra database.</p>

<p>Both the application server and the tile generation service use Nginx, uWSGI and flask to host
their content.  For the application server, this means transforming HTTP requests into database
accesses and/or serving content (code <a href="https://github.com/google/jsonnet/blob/master/case_studies/appserv/main.py">here</a>).  For the tile
generation service, this means invoking a compiled C++ <a
href="https://github.com/google/jsonnet/blob/master/case_studies/tilegen/mandelbrot.cpp">executable</a> from the Flask <a
href="https://github.com/google/jsonnet/blob/master/case_studies/tilegen/mandelbrot_service.py">handler</a> in order to construct a PNG for a given
tile / thumbnail of the fractal.  Both tiers consist of a group of <a
href="https://cloud.google.com/compute/docs/instances">instances</a> behind a <a
href="https://cloud.google.com/compute/docs/load-balancing/network/">layer 3 cloud load balancer</a>
with a static IP and a simple <a
href="https://cloud.google.com/compute/docs/load-balancing/health-checks">health check</a>.  The
Cassandra database is simply a set of instances, as the Cassandra client library (used by the
application server) does client-side load balancing and transparent failover, thus does not need a
cloud load balancer.</p>

<p>The application is deployed by first using Packer to build a image for each of the 3 kinds of
cloud instances (application server, fractal image processing service, Cassandra).  Then, all the
cloud resources (instances, load balancers, etc) are deployed using Terraform.  The Packer build
compiles, installs and configures all of the required software on each image.  The Terraform
configuration provides last minute configuration (host:port endpoints, passwords, etc) to the
instances via <a href="https://cloud.google.com/compute/docs/metadata">metadata</a>.</p>

<p>The choice about what configuration to provide at image build time (embedded in Packer
configurations) vs deployment time (embedded in Terraform configuration) is up to the user.  The
advantage of doing more at image build time is that instances can then be deployed more quickly
(useful in an auto-scaling situation).  But allowing some configuration at deployment time makes the
images more flexible.  Some configuration (e.g. host:port endpoints) is only known at deployment
time so must be specified in the Terraform configuration.  In our case, we try to do all time
consuming steps (downloading, generating, compiling) in Packer, while leaving finer details until
deployment.</p>


<h2 id=config>Configuration Structure</h2>

<p>This example is configured with a single Jsonnet <i>configuration</i>, which is logically
separated into several files via the <code>import</code> constructs.  This is to promote abstraction
and re-usability, as well as having a separate credentials file (to avoid accidental checkin).  Note
that Jsonnet did not mandate this structure:  Other separations (or a giant single file) would also
have been possible.</p>

<p>This single configuration yields the a JSON packer configuration for each image (*.packer.json)
and the JSON Terraform configuration (terraform.tf), using <a href="commandline.html#multi">multiple
file output</a>.  Those configurations in turn embed other configurations for the application
software that will run on the instances.  The top-level structure of the generated configuration is
therefore as follows (with the content of each file elided for clarity).</p>

<pre class="large"><code> {
    "appserv.packer.json": ...,
    "cassandra.packer.json": ...,
    "tilegen.packer.json": ...,
    "terraform.tf": ...,
}
</code></pre>

<p>The configuration is specified by the following input Jsonnet files:</p>











<ul>

<li><tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt>: The top level file that imports the others.  This is the filename that
is given to the jsonnet commandline utility.  In it are all the details that define the Fractal
example application, as a list of packer images and a Terraform configuration.  Note the first few
lines import the other Jsonnet files and store their contents in top-level scoped variables (of the
same names).  When we access things from those libraries (e.g. when overriding templates) we will do
so through the top-level variables.</li>

<li><tt>credentials.jsonnet</tt>: User and superuser keys for Cassandra, and Google Cloud Platform
project name.  You must create this file yourself.  For convenience, there is a  <a
href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/credentials.jsonnet.TEMPLATE">template</a>.</li>

<li><tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/packer.jsonnet">lib/packer.jsonnet</a></tt>: Some templates to help with writing Packer configurations.</li>

<li><tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/terraform.jsonnet">lib/terraform.jsonnet</a></tt>: Some templates to help with writing Terraform
configurations.</li>

<li><tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/cassandra.jsonnet">lib/cassandra.jsonnet</a></tt>: Some templates to help with writing Packer and Terraform
configurations for Cassandra.</li>

</ul>

<p>Note that the Jsonnet template libraries also include some definitions not used in this
example application, e.g.  PostgreSQL and MySQL templates.  Those can be ignored.</p>

<p>To integrate Jsonnet with Packer and Terraform, a <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/Makefile">Makefile</a></tt> is used.  This first runs
Jsonnet on the configuration and then runs Packer / Terraform on the resulting files (if they have
changed).  The choice of 'glue' tool is arbitrary, we could also have used a small Python script.
We chose make because it is well understood, available everywhere, and does 3 things that we want:
Invoke other programs, run things in parallel, and avoid repeating work that is already complete.
For example, Packer is only invoked if its configuration file has changed, and the 3 image builds
will proceed in parallel (they take a few minutes each).</p>

<p>Ignoring the re-usable templates, whitespace, and comments, the Jsonnet configuration is 217
lines (9.7kB).  The generated Packer and Terraform files are 740 lines (25kB) in total.  This
demonstrates the productivity benefits of using template expansion when writing configurations.</p>


<h3 id=config_whirlwind>Whirlwind Tour</h3>

<p> The fractal example is a complete application and therefore its configuration is quite long and
technical.  It also embeds configurations for the various pieces of off-the-shelf software used, so
quite a lot of domain knowledge is required to fully understand it.  Our intention in this article
is merely to highlight some of the more interesting features.  We'll gladly field specific questions
on the <a href="https://groups.google.com/forum/#!forum/jsonnet">mailing list</a>.</p>


<h4>Packer And Application Configuration</h4>

<p>The <code>ImageMixin</code> object in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> is used to factor out common
configuration from the 3 images (Packer configurations).  This includes the Google Cloud Platform
project id and filename of the service account key.  Since all the images are derived ultimately
from the <code>GcpDebian</code> image (in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/packer.jsonnet">lib/packer.jsonnet</a></tt>), and this image includes apt
&amp; pip provisioners (discussed shortly), this is also a good place to ensure some basic packages
are installed on every image.  Note that since this object is not intended to be actually created
(it existing only for reference from other parts of the configuration) it is stored in a hidden
field (:: syntax).</p>

<p>Both the application server's image configuration <tt>appserv.packer.json</tt> and the tile
generation service's image configuration <tt>tilegen.packer.json</tt> extend
<code>MyFlaskImage</code>, which exists merely to add the aforementioned <code>ImageMixin</code> to
the <code>GcpDebianNginxUwsgiFlaskImage</code> template from <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/packer.jsonnet">lib/packer.jsonnet</a></tt>.  That template
builds on the basic <code>GcpDebianImage</code> template from the same library, and adds all the
packages (and default configuration) for both Nginx and uWSGI.</p>

<p>In Jsonnet we use JSON as the canonical data model and convert to other formats as needed.  An
example of this is the uWSGI configuration, an <a
href="http://en.wikipedia.org/wiki/INI_file">INI</a> file, which specified in Jsonnet under the
<code>uwsgiConf</code> field in <code>GcpDebianNginxUwsgiFlaskImage</code>.  The JSON version is
converted to INI by the call to <code>std.manifestIni</code> (documented <a
href="stdlib.html">here</a>) in the provisioner below.  Representing the INI file with the JSON
object model (instead of as a string) allows elements of the uWSGI configuration, such as the
filename of the UNIX domain socket, to be easily kept in sync with other elements of the
configuration, e.g. the Nginx configuration file below needs the same filename.  If the application
is configured with JSON, or even YAML, then no conversion is required.  An example of that is the
default Cassandra configuration file held in the <code>conf</code> field of
<tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/cassandra.jsonnet">lib/cassandra.jsonnet</a></tt>.</p>

<p>Looking back at <tt>appserv.packer.json</tt> and <tt>tilegen.packer.json</tt> in
<tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt>, while both use Nginx/uWSGI/Flask there are some subtle differences.  Since
the HTTP request handlers are different in each case, the module (uWSGI entrypoint) and also
required packages are different.  Firstly, the tile generation image needs a provisioner to build
the C++ code.  Secondly, since the application server talks to the Cassandra database using
cassandra-driver, which interferes with pre-forking, it was necessary to override the
<code>lazy</code> field of the uWSGI configuration in that image.  This is an example of how an
abstract template can unify two similar parts of the configuration, while still allowing the
overriding of small details as needed.  Note also that such precise manipulation of configuration
details would be much harder if the uWSGI configuration was represented as a single string instead
of as a structure within the object model.</p>

<p>Going up to the top of the template hierarchy we have <code>GcpDebianImage</code> and finally
<code>GcpImage</code> in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/packer.jsonnet">lib/packer.jsonnet</a></tt>.  The latter gives the Packer builder configuration
for Google Cloud Platform, bringing out some fields to the top level, essentially hiding the
<code>builder</code> subobject.  We can hide the builder configuration because we only ever need one
builder per image.  We can support multiple cloud providers by deriving an entire new Packer
configuration at the top level, overriding as necessary to specialize for that platform.  The
<code>GcpDebianImage</code> selects the base image (Backports) and adds provisioners for apt and pip
packages.  The configuration of those provisioners (the list of installed packages, and additional
repositories / keys) is brought out to the top level of the image configuration.  By default, the
lists are empty but subobjects can override and extend them as we saw with
<code>GcpDebianNginxUwsgiFlaskImage</code>.</p>

<p>The actual provisioners <code>Apt</code> and <code>Pip</code> are defined further up
<tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/packer.jsonnet">lib/packer.jsonnet</a></tt>.  In their definitions, one can see how the various shell commands are built
up from the declarative lists of repositories, package names, etc.  Installing packages in a
non-interactive context requires a few extra switches and an environment variable, but the
<code>Apt</code> provisioner handles all that.  Also note how these provisioners both derive from
<code>RootShell</code> (defined right at the top of the file) because those commands need to be run
as root.  All of this is plain Jsonnet code, so it is possible to create your own provisioners
(based on these or from scratch) in order to declaratively control packages in a Packer image.</p>


<h4>Terraform</h4>

<p>The remainder of <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> is the Terraform configuration that defines all the
cloud resources that are required to run the fractal web application.  That includes the instances
of the images built by Packer, but also resources that configure network routing / firewalls, load
balancers, etc.  Terraform accepts two basic syntaxes, JSON and <a
href="https://github.com/hashicorp/hcl">HCL</a> (a more concise form of JSON).  This provides a
datastructure that specifies the resources required, but the model also has a few computational
features:  The structure has 'variables' which an be resolved by <a
href="http://en.wikipedia.org/wiki/String_interpolation">string interpolation</a> within the
resources.  All resources are also extended with a <tt>count</tt> parameter for creating <i>n</i>
replicas of that resource, and there is also some support for importing 'modules', i.e. another
configuration of resources defined by a third party.</p>

<p>The interpolation feature is also used to reference attributes of resources that are not known
until after deployment (i.e. cannot be known during Jsonnet execution time).  For example, the
generated IP address of a static IP resource called <tt>foo</tt> can be referenced from a string in
the definition of a resource <tt>bar</tt> using the syntax
<tt>${google_compute_address.foo.address}</tt>, which is resolved after the deployment of the
<tt>foo</tt> in time for the deployment of <tt>bar</tt>.</p>

<p>We choose to emit JSON instead of building an HCL manifestation layer.  We also do not make use
of any of the Terraform language features, as Jsonnet provides similar or greater capabilities in
each of those domains, and doing it at the Jsonnet level allows integration with the rest of the
configuration.  We do, however, use Terraform interpolation for resolving the "not known until
deployment" attributes.  For example, in order to configure the application server with the
host:port endpoint of the tile processing service.  Such resolution can only be performed by
Terraform and is an irreplaceable part of any deployment agent.</p>

<p>Going through <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt>, the function <code>zone</code> is used to statically
assign zones to instances on a round robin basis.  All the instances extend from
<code>FractalInstance</code>, which is parameterized by the index <code>zone_hash</code> (it's
actually just a function that takes zone_hash and returns an instance template).  It is this index
that is used to compute the zone, as can be seen in the body of <code>FractalInstance</code>.  The
zone is also also a namespace for the instance name, so when we list the instances behind each load
balancer in the <code>google_compute_target_pool</code> object, we compute the zone for each
instance there as well.</p>

<p><code>FractalInstance</code> also specifies some default API access scopes and tags, as well as
the network over which the instances communicate.  It extends <code>GcpInstance</code> from
<tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/terraform.jsonnet">lib/terraform.jsonnet</a></tt>, which brings default service account scopes, the network, and the
startup script to the top level, and provides some defaults for other parameters.</p>

<p>Back in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> we now have the instance definitions themselves, which are
replicas of one of 3 different images: application server, db (Cassandra) and tile generation.
Terraform takes the instances in the form of a map (i.e. a JSON object), since it identifies them
internally with unique string names.  The instances are defined as a group for each image, and these
3 objects are composed with the object addition <code>+</code> operator.</p>

<p>The appserv and tilegen replicas are given using an object comprehension in which the field name
and value are computed with <code>k</code> set to each index in the given list.  The variable
<code>k</code> also ends up as an argument to <code>FractalInstance</code> and thus defines the
zone.  In both cases, we also place a file <tt>/var/www/conf.json</tt>.  This is read by the Python
code at startup and used to configure the service.  In the tilegen replicas the configuration comes
from <code>ApplicationConf</code> from the top of the file.  In the appserv instances, this
configuration is extended with some extra fields before being put in the file.  In both cases, the
startup script has added an extra line, computed by <code>self.addFile()</code>, a method (i.e. a
field containing a function) inherited from <code>GcpInstance</code> in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/lib/terraform.jsonnet">lib/terraform.jsonnet</a></tt>.
Examining its definition shows that it uses echo to write the given content to the given filename.  
</p>

<p>Cassandra deployment, starter mixin, initcql</p>

<h2 id=using>Using The Configuration</h2>

<p>The rest of this article gives simple methodologies for deploying and managing the example
application by applying changes to the Jsonnet configuration.  In order to reproduce this case study
there are a few pre-requisites:</p>

<ul>

<li>A Linux or OSX system with GNU Make</li>

<li>Packer, built from github, in your $PATH.</li>

<li>Terraform, including <a href="https://github.com/hashicorp/terraform/pull/588">PR #588</a>, in
your $PATH.</li>

<li>Jsonnet, built from github (this is also where you find the configuration and source code).</li>

<li>An account on Google Cloud Platform (hosting the application will incur charges).</li>

</ul>

<p>Once those are satisfied, follow these steps:</p>

<ol>

<li>In the Google Cloud Platform console, open your project, go to APIs and Auth / credentials, and
create a new service account.  This will automatic download a p12 key, which you can delete as we
will not be using it.  Instead, click the button to download a JSON key for the new service account,
move it to the fractal directory, and call it <tt>service_account_key.json</tt>.</li>

<li>Create a credentials.jsonnet file based on the template, fill in your GCP project name and make
up some unique passwords.</li>

</ol>

<h3 id=using_deploy>Initial Deployment and Tear Down</h3>

<p>To deploy the app, run make -j.  This should start running 3 Packer builds in parallel.  In a
separate terminal, use tail -f *.log in order to watch their progress.  When the images are built,
Terraform is run and will show you the proposed changes.  Enter y to confirm the changes.  In time,
the application will be deployed.  Now you only need the appserv ip address to connect to it.  You
can get this using "gcloud compute addresses list" or by navigating the Google Cloud Platform
console to "networks".  Opening that ip in a web browser should take you to the application itself.
</p>

<p>The application can be brought down again with terraform destroy.  This will not destroy the
Packer images, they can be deleted from the console or from gcloud.</p>

<p>Managing a production web service usually means making continual changes to it instead of
bringing the whole thing down and up again.  However it is still useful to do this for development
or testing purposes.  A copy or variant of the production service can be brought up concurrently
with the production service (e.g. in a different project).  This can be useful for QA, automatic
integration testing, or load testing.  It is also useful for training new staff or simulating a
production change in a safe environment.</p>

<h3 id=using_cassandra>Add / Remove Cassandra Nodes</h3>

<p>Managing the Cassandra cluster requires a combination of configuration alteration (to control the
fundamental compute resources) and use of the Cassandra commandline tool "nodetool" on the instances
themselves.  For example "nodetool status fractal" on any Cassandra instance will give information
about the whole cluster.</p>

<p>To add a new node (expand the cluster), simply edit <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt>, add another
instance in the Terraform configuration and run make -j.  Confirm the changes (the only change
should be the new instance, e.g. db4).  It will start up and soon become part of the cluster.</p>

<p>To remove a node, first decommission it using nodetool -h HOSTNAME decommission.  When that is
complete, destroy the actual instance by updating <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> to remove the resource
and run make -j again.  Confirm the removal of the instance.</p>

<p>If a node is permanently and unexpectedly lost (e.g. a disk error), or you removed it without
first decommissioning it, the cluster will expect it to return at some point (as if it were
temporarily powered down or on the wrong side of a network split).  This situation an be rectified
with nodetool removenode UUID, run from any other node in the cluster.  It is probably also
necessary to run nodetool repair on the other nodes to ensure data is properly distributed.</p>


<h3 id=using_appserv>Canary A Change To The Application Server</h3>

<p>To introduce new functionality to the application server it is useful to divert a small
proportion of user traffic to the new code to ensure it is working properly.  After this initial
"canary" test has passed, the remaining traffic will be transferred as well.  This process is the
same for the tile generation service (e.g. to update the C++ code).</p>

<p>The model employed by this example is that the application server logic and static content are
embedded in the application server image.  Canarying consists of building a new image and then
rolling it out gradually one step at a time.  Each step consists of a small modification to
<tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> and then running make -j.</p>

<ol>

<li>Edit the <tt>appserv.packer.json</tt> packer configuration in <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt> to update
the date embedded in the <tt>name</tt> field to the current date, and also make any desired changes
to the configuration of the image or any of the referenced Python / HTML / CSS files.</li>

<li>Run make -j to build the new image.  Note that the previous image is still available under the
old name, which means it is possible to create new instances using either the old or new image.
This feature is essential to allow ongoing maintenance of the cluster if the change is rolled
back.</li>

<li>Create a single instance with the new image by adding it to the <tt>google_compute_instance</tt>
section of <tt><a href="https://github.com/google/jsonnet/blob/master/case_studies/fractal/service.jsonnet">service.jsonnet</a></tt>.  The easiest way to do this is to copy-paste the existing
definition, and modify the image name in the copy to reflect the new image.  This allows easily
rolling back by deleting the copied code, and you can also transition the rest of the nodes by
deleting the original copy.  Thus the duplication is only temporary.  The configuration may look
like this:

<pre class="large"><code>google_compute_instance: {

    ["appserv" + k]: resource.FractalInstance(k) {
        name: "appserv" + k,
        image: "appserv-v20141222-0300",
        ...
    }
    for k in [1, 2, 3]

} + {

    ["appserv" + k]: resource.FractalInstance(k) {
        name: "appserv" + k,
        image: "appserv-v20150102-1200",
        ...
    }
    for k in [4]

} + ...
</code></pre>

Also modify the appserv target pool to add the new instance 4, thus ensuring it receives
traffic.</li>

<pre class="large"><code>appserv: {
    name: "appserv",
    health_checks: ["${google_compute_http_health_check.fractal.name}"],
    instances: [ "%s/appserv%d" % [zone(k), k] for k in [1, 2, 3, 4] ],
},
</code></pre>
</li>

<li>Run make -j to effect those changes, and monitor the situation to ensure that there is no spike
in errors.  It is also possible to run make -j between the above two steps if it is desired to
interact with the new instance before directing user traffic at it.</li>

<li>If there is a problem, pull 4 out of the target pool and re-run make -j.  That will leave the
instance up (useful for investigation) but it will no-longer receive user traffic.  Otherwise, add
more instances (5, 6, ...) and add them to the target pool.  You can now start pulling the old
instances out of the target pool ensuring that there is always sufficient capacity for your traffic
load.  As always, make -j punctuates the steps.</li>

<li>Once the old instances are drained of user traffic, they can be destroyed.  You can do this in
batches or one at a time.  Eventually the configuration will look like this, at which point the
first block no-longer contributes anything to the configuration and it can be deleted. 

<pre class="large"><code>google_compute_instance: {

    ["appserv" + k]: resource.FractalInstance(k) {
        name: "appserv" + k,
        image: "appserv-v20141222-0300",
        ...
    }
    for k in []

} + {

    ["appserv" + k]: resource.FractalInstance(k) {
        name: "appserv" + k,
        image: "appserv-v20150102-1200",
        ...
    }
    for k in [4, 5, 6]

} + ...
</code></pre>
</li>

</ol>

<h2 id=conclusion>Conclusion</h2>

<p>We have shown how Jsonnet can be used to centralize, unify, and manage configuration for a
realistic cloud application.  We have demonstrated how programming language abstraction techniques
make the configuration very concise, with re-usable elements separated into template libraries.
This is in spite of the variety of different configurations, formats, and tasks, that we brought
under our control.</p>

<p>We demonstrated how with a little procedural glue to drive other processes (make), we were able
to build an operations methodology where all aspects of running the service are controlled by
editing a single Jsonnet file and issuing an update command.</p>

<div style="margin-bottom: 50px"></div>
<hr />
<p class="copyright">
Except as noted, this content is licensed under Creative Commons Attribution 2.5.
</p>
</body>

</html>